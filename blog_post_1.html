<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TD Learning with Linear Function Approximation in State-Aggregated Environments</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #1F1F1F;
            color: #E6E6E6;
            line-height: 1.6;
        }
        header {
            background-color: #E6E6E6;
            color: #1F1F1F;
            padding: 2em 1em;
            text-align: center;
        }
        nav {
            background-color: #E6E6E6;
            text-align: center;
        }
        nav a {
            color: #1F1F1F;
            padding: 1em;
            text-decoration: none;
            transition: background-color 0.3s ease, border-radius 0.3s ease;
        }
        nav a:hover {
            background-color: #D6596C;
            border-radius: 15px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2em;
        }
        .section {
            margin: 2em 0;
        }
        .section h2, .section h3 {
            color: #D6596C;
        }
        .theorem {
            margin: 1em 0;
            padding: 1em;
            background-color: rgba(214, 89, 108, 0.1);
            border-left: 4px solid #D6596C;
        }
        .lemma {
            margin: 1em 0;
            padding: 1em;
            background-color: rgba(214, 89, 108, 0.05);
            border-left: 4px solid #D6596C;
        }
        .proof {
            margin: 1em 0;
            padding: 1em;
            background-color: rgba(230, 230, 230, 0.05);
        }
        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 1em 0;
            position: fixed;
            width: 100%;
            bottom: 0;
        }
    </style>
</head>
<body>
    <header>
        <h1>TD Learning with Linear Function Approximation in State-Aggregated Environments</h1>
        <p>Hirsa Kia - August 2024</p>
    </header>
    <nav>
        <a href="#abstract">Abstract</a>
        <a href="#introduction">Introduction</a>
        <a href="#definitions">Definitions</a>
        <a href="#assumptions">Assumptions</a>
        <a href="#transformations">Transformations</a>
        <a href="#scenario1">Scenario 1</a>
        <a href="#scenario2">Scenario 2</a>
        <a href="#outcomes">Outcomes</a>
    </nav>
    <div class="container">
        <section id="abstract" class="section">
            <h2>Abstract</h2>
            <p>We analyze the convergence of TD learning with linear function approximation through the lens of optimization and target forces in state-aggregated environments. Using matrix decomposition and eigenvalue analysis, we examine three scenarios: standard unit directions, one-dimensional, and n-dimensional feature spaces. Our analysis proves that convergence is independent of feature space dimensionality and requires only the existence of a suitable probability distribution. We show these convergence properties hold across scalar and tabular cases. The results extend to cases where the feature norm equality assumption is relaxed to parent's feature norm larger than expectation of feature norms of the children.</p>
        </section>

        <section id="definitions" class="section">
            <h2>Definitions</h2>
            <p>We define \(\phi_i\) as the feature of state \(i\), where \(\phi_i=\|\phi_i\|e_i\) with \(\|\phi_i\|\) as its norm and \(e_i\) as its direction in the form of a row vector (we assume \(\|\phi_i\|=1\) for all the states). Rows of matrix \(\Phi\) are features \(\phi_i\) of each state. Matrix \(D\) is a diagonal matrix with entries \(d_i\) less than one and trace equal to 1. \(ij\)-th element of probability transition matrix \(P\), written as \(P_{ij}\), is equivalent to \(P(s_j|s_i)\).</p>
        </section>

        <section id="transformations" class="section">
            <h2>Transforming the Original Formulation</h2>
            <p>Using the notion of optimization and target forces, optimization force can be written as:</p>
            \[ M_w=\Phi^\top D \Phi=\sum_{i=1}^n d_i e_i^\top e_i \]
            
            <p>Assume some of the states are aligned, creating clusters with the same direction. We can write:</p>
            \[ M_w=\Phi^\top D \Phi=\sum_{S_i\subset S} \Bigl(\sum_{s\in S_i} d(s) \Bigr) e_i^\top e_i \]
            
            <p>We can now invert \(M_w\):</p>
            \[ M_w^{-1} = \sum_{i=1}^m \frac{1}{\lambda_i} e_i^\top e_i = \sum_{S_i \subset S} \frac{1}{\sum_{s \in S_i} d(s)} e_i^\top e_i \]
        </section>

        <section id="scenario1" class="section">
            <h2>Scenario 1: Standard Unit Directions</h2>
            <p>For parents in \(S_p\) (corresponding to row \(p\) of the matrix) we can write:</p>
            \[ \gamma e_p^\top \frac{1}{\sum_{s \in S_p} d(s)} \sum_{s \in S_p} d(s) \Big(\sum_{s^\prime \in S_1} P(s^\prime | s) e_1 + \cdots + \sum_{s^\prime \in S_m} P(s^\prime | s) e_m \Big) \]

            <div class="lemma">
                <h3>Lemma 1</h3>
                <p>Matrix \((M_w)^{-1}M_{\theta}\) is a stochastic matrix.</p>
            </div>

            <div class="proof">
                <h3>Proof</h3>
                <p>To show that a given matrix is a stochastic matrix, we need to prove that it has no negative entry and the summation of each row is equal to 1. Since each term is a non-negative value the first part is proved.</p>
                
                <p>For the second part we can write:</p>
                \[ \frac{1}{\sum_{s\in S_p}d(s)}\sum_{s\in S_p} d(s) = 1 \]
            </div>
        </section>

        <section id="scenario2" class="section">
            <h2>Scenario 2: Orthonormal Directions</h2>
            <p>We drop the Cartesian unit vector assumption. Here we only assume that the state features are orthonormal to each other.</p>

            <h3>1-Dimensional Feature Space</h3>
            <p>In case of scalar features, since there is only one direction, we have only one cluster (\(S = S_1\)). The equation becomes:</p>
            \[ \gamma (M_w)^{-1} M_{\theta} = \frac{\gamma \sum_{i=1}^n d(s) \sum_{j=1}^n P(s^\prime | s)}{\sum_{k=1}^n d(s)} \]
        </section>

        <section id="outcomes" class="section">
            <h2>Outcomes</h2>
            <p>In all three scenarios we observed that:</p>
            <ul>
                <li>Convergence does not depend on the feature space size.</li>
                <li>Convergence does not depend on the form of update distribution \(D\). The sole existence of such probability distribution makes the convergence possible.</li>
            </ul>
        </section>
    </div>
    <footer>
        <p>&copy; 2024 Hirsa Kia</p>
    </footer>
</body>
</html>
